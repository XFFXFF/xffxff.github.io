{"pageProps":{"postData":{"id":"14_autogpt_learn","contentHtml":"<p>项目地址：<a href=\"https://github.com/Significant-Gravitas/Auto-GPT\">https://github.com/Significant-Gravitas/Auto-GPT</a></p>\n<h2>Prompt 构造</h2>\n<p>AutoGPT 的 prompt <a href=\"https://github.com/Significant-Gravitas/Auto-GPT/blob/fdd79223b0c6132e1d7fc5127e9ca02fabaea9e5/autogpt/chat.py#L27-L49\">包含多条 message</a></p>\n<p>这里主要看看其中一条，也是最主要的</p>\n<pre><code>You are Tennis-GPT, An AI for creating tennis training plan\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\n\nGOALS:\n\n1. Aim to achieve an amateur level of 2.5 for tennis beginners.\n2. Practice at home.\n\n\nConstraints:\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\n3. No user assistance\n4. Exclusively use the commands listed in double quotes e.g. \"command name\"\n\nCommands:\n1. Google Search: \"google\", args: \"input\": \"&#x3C;search>\"\n2. Browse Website: \"browse_website\", args: \"url\": \"&#x3C;url>\", \"question\": \"&#x3C;what_you_want_to_find_on_website>\"\n3. Start GPT Agent: \"start_agent\", args: \"name\": \"&#x3C;name>\", \"task\": \"&#x3C;short_task_desc>\", \"prompt\": \"&#x3C;prompt>\"\n4. Message GPT Agent: \"message_agent\", args: \"key\": \"&#x3C;key>\", \"message\": \"&#x3C;message>\"\n5. List GPT Agents: \"list_agents\", args:\n6. Delete GPT Agent: \"delete_agent\", args: \"key\": \"&#x3C;key>\"\n7. Clone Repository: \"clone_repository\", args: \"repository_url\": \"&#x3C;url>\", \"clone_path\": \"&#x3C;directory>\"\n8. Write to file: \"write_to_file\", args: \"file\": \"&#x3C;file>\", \"text\": \"&#x3C;text>\"\n9. Read file: \"read_file\", args: \"file\": \"&#x3C;file>\"\n10. Append to file: \"append_to_file\", args: \"file\": \"&#x3C;file>\", \"text\": \"&#x3C;text>\"\n11. Delete file: \"delete_file\", args: \"file\": \"&#x3C;file>\"\n12. Search Files: \"search_files\", args: \"directory\": \"&#x3C;directory>\"\n13. Evaluate Code: \"evaluate_code\", args: \"code\": \"&#x3C;full_code_string>\"\n14. Get Improved Code: \"improve_code\", args: \"suggestions\": \"&#x3C;list_of_suggestions>\", \"code\": \"&#x3C;full_code_string>\"\n15. Write Tests: \"write_tests\", args: \"code\": \"&#x3C;full_code_string>\", \"focus\": \"&#x3C;list_of_focus_areas>\"\n16. Execute Python File: \"execute_python_file\", args: \"file\": \"&#x3C;file>\"\n17. Generate Image: \"generate_image\", args: \"prompt\": \"&#x3C;prompt>\"\n18. Send Tweet: \"send_tweet\", args: \"text\": \"&#x3C;text>\"\n19. Convert Audio to text: \"read_audio_from_file\", args: \"file\": \"&#x3C;file>\"\n20. Do Nothing: \"do_nothing\", args:\n21. Task Complete (Shutdown): \"task_complete\", args: \"reason\": \"&#x3C;reason>\"\n\nResources:\n1. Internet access for searches and information gathering.\n2. Long Term memory management.\n3. GPT-3.5 powered Agents for delegation of simple tasks.\n4. File output.\n\nPerformance Evaluation:\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\n2. Constructively self-criticize your big-picture behavior constantly.\n3. Reflect on past decisions and strategies to refine your approach.\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\n\nYou should only respond in JSON format as described below\nResponse Format:\n{\n    \"thoughts\": {\n        \"text\": \"thought\",\n        \"reasoning\": \"reasoning\",\n        \"plan\": \"- short bulleted\\n- list that conveys\\n- long-term plan\",\n        \"criticism\": \"constructive self-criticism\",\n        \"speak\": \"thoughts summary to say to user\"\n    },\n    \"command\": {\n        \"name\": \"command name\",\n        \"args\": {\n            \"arg name\": \"value\"\n        }\n    }\n}\nEnsure the response can be parsed by Python json.loads\n</code></pre>\n<blockquote>\n<p>上述 prompt 中关于 tennis 的部分是可变的，是我输入给它的</p>\n</blockquote>\n<p>这段 prompt 中我能够快速学到的经验是，如果想得到一些格式化的输出，可以直接让 GPT 生成 JSON 字符串。</p>\n<pre><code>You should only respond in JSON format as described below\nResponse Format:\n{\n    \"thoughts\": {\n        \"text\": \"thought\",\n        \"reasoning\": \"reasoning\",\n        \"plan\": \"- short bulleted\\n- list that conveys\\n- long-term plan\",\n        \"criticism\": \"constructive self-criticism\",\n        \"speak\": \"thoughts summary to say to user\"\n    },\n    \"command\": {\n        \"name\": \"command name\",\n        \"args\": {\n            \"arg name\": \"value\"\n        }\n    }\n}\nEnsure the response can be parsed by Python json.loads'\n</code></pre>\n<p>我之前的做法是让 GPT 生成纯文本，然后用正则去匹配，除了正则匹配麻烦之外，生成纯文本并不一定会完全按照预期的格式，比如如下 prompt</p>\n<pre><code>You should only respond as described below\noptions:\n    1. option 1\n    2. option 2\n</code></pre>\n<p>GPT 可能会自由发挥一下，生成</p>\n<pre><code>your options are:\n    1. option 1\n    2. option 2\n</code></pre>\n<p>Prompt 中其他 trick 还待我继续探索。</p>\n<h2>记忆</h2>\n<p>为什么需要记忆，和 GPT 多轮对话时，把所有聊天历史都输入给 GPT，token 数量不够，所以希望把历史会话存储下来，下次和 GPT 对话时，冲历史对话（记忆）中找到相关的内容，然后把相关的内容输入给 GPT，这样 GPT 就可以更好的理解当前的对话。</p>\n<p>主要看看 <a href=\"https://github.com/Significant-Gravitas/Auto-GPT/blob/fdd79223b0c6132e1d7fc5127e9ca02fabaea9e5/autogpt/memory/local.py#L29\">LocalCache</a> 中 <a href=\"https://github.com/Significant-Gravitas/Auto-GPT/blob/fdd79223b0c6132e1d7fc5127e9ca02fabaea9e5/autogpt/memory/local.py#L62\">add</a> 和 <a href=\"https://github.com/Significant-Gravitas/Auto-GPT/blob/fdd79223b0c6132e1d7fc5127e9ca02fabaea9e5/autogpt/memory/local.py#L113\">get_relevant</a> 的实现</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">add</span>(<span class=\"hljs-params\">self, text: <span class=\"hljs-built_in\">str</span></span>):\n    // 存储原始的 text\n    self.data.texts.append(text)\n\n    embedding = create_embedding_with_ada(text)\n\n    vector = np.array(embedding).astype(np.float32)\n    vector = vector[np.newaxis, :]\n    // 存储 text 对应的 embedding\n    self.data.embeddings = np.concatenate(\n        [\n            self.data.embeddings,\n            vector,\n        ],\n        axis=<span class=\"hljs-number\">0</span>,\n    )\n</code></pre>\n<p>根据当前的 text 的 embedding，和历史对话中的所有 text 的 embedding 计算点积，然后取 top k，返回相关的 text</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">get_relevant</span>(<span class=\"hljs-params\">self, text: <span class=\"hljs-built_in\">str</span>, k: <span class=\"hljs-built_in\">int</span></span>) -> <span class=\"hljs-built_in\">list</span>[<span class=\"hljs-type\">Any</span>]:\n    embedding = create_embedding_with_ada(text)\n\n    scores = np.dot(self.data.embeddings, embedding)\n\n    top_k_indices = np.argsort(scores)[-k:][::-<span class=\"hljs-number\">1</span>]\n\n    <span class=\"hljs-keyword\">return</span> [self.data.texts[i] <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> top_k_indices]\n</code></pre>","title":"向 AutoGPT 学习如何发挥 GPT 的潜力","date":"2023-04-19"}},"__N_SSG":true}