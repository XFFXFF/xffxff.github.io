<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.6.0/styles/github.min.css"/><title>FLOPs 的计算</title><meta name="next-head-count" content="4"/><link rel="preload" href="/_next/static/css/ab65974685f462b8.css" as="style"/><link rel="stylesheet" href="/_next/static/css/ab65974685f462b8.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js"></script><script src="/_next/static/chunks/webpack-8fa1640cc84ba8fe.js" defer=""></script><script src="/_next/static/chunks/framework-6cbe6e332df95288.js" defer=""></script><script src="/_next/static/chunks/main-26f9f36b33181737.js" defer=""></script><script src="/_next/static/chunks/pages/_app-2d6bf7b3192a8752.js" defer=""></script><script src="/_next/static/chunks/73-96e6cbd54826b874.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bid%5D-4b57e02c440700a5.js" defer=""></script><script src="/_next/static/wTPBy1ZzrXj1NkuaydzLJ/_buildManifest.js" defer=""></script><script src="/_next/static/wTPBy1ZzrXj1NkuaydzLJ/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="max-w-4xl px-4 mt-12 mb-24 mx-auto"><main><article><h1 class="text-3xl font-medium my-4 border-b-0">FLOPs 的计算</h1><div class="text-gray-500 mb-8 pb-2 border-b-2 border-solid border-slate-300"><time dateTime="2024-04-18">April 18, 2024</time></div><div><p>模型训练过程中大多数浮点运算都是矩阵乘法，对于一个 <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>×</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">m \times n</annotation></semantics></math></span> 的矩阵 <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span> 和一个 <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>×</mo><mi>p</mi></mrow><annotation encoding="application/x-tex">n \times p</annotation></semantics></math></span> 的矩阵 <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span>，<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>×</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">A \times B</annotation></semantics></math></span> 需要 <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>×</mo><mi>n</mi><mo>×</mo><mi>p</mi></mrow><annotation encoding="application/x-tex">m \times n \times p</annotation></semantics></math></span> 次乘法和 <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>×</mo><mi>n</mi><mo>×</mo><mi>p</mi></mrow><annotation encoding="application/x-tex">m \times n \times p</annotation></semantics></math></span> 次加法，即需要 <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>m</mi><mi>n</mi><mi>p</mi></mrow><annotation encoding="application/x-tex">2mnp</annotation></semantics></math></span> FLOPs。</p>
<h2>Transformer Architecture 的 FLOPs 计算</h2>
<p><img src="/transformer.png" alt="alt text"></p>
<p><img src="/attention.png" alt="alt text"></p>
<h3>Attention</h3>
<p>Q，K，V transformation:  <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>×</mo><mn>2</mn><mi>B</mi><mi>s</mi><msup><mi>h</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">3 \times 2Bsh^2</annotation></semantics></math></span></p>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">QK^T</annotation></semantics></math></span>: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>B</mi><msup><mi>s</mi><mn>2</mn></msup><mi>h</mi></mrow><annotation encoding="application/x-tex">2Bs^2h</annotation></semantics></math></span></p>
<p>attention over values: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>B</mi><msup><mi>s</mi><mn>2</mn></msup><mi>h</mi></mrow><annotation encoding="application/x-tex">2Bs^2h</annotation></semantics></math></span></p>
<p>post-attention linear projection: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>B</mi><mi>s</mi><msup><mi>h</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">2Bsh^2</annotation></semantics></math></span></p>
<h3>Feed Forward Network</h3>
<p>linear h->4h: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8</mn><mi>B</mi><mi>s</mi><msup><mi>h</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">8Bsh^2</annotation></semantics></math></span></p>
<p>linear 4h->h: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8</mn><mi>B</mi><mi>s</mi><msup><mi>h</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">8Bsh^2</annotation></semantics></math></span></p>
<h3>Total</h3>
<p>forward: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>6</mn><mo>+</mo><mn>2</mn><mo>+</mo><mn>8</mn><mo>+</mo><mn>8</mn><mo stretchy="false">)</mo><mi>B</mi><mi>s</mi><msup><mi>h</mi><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mn>2</mn><mo>+</mo><mn>2</mn><mo stretchy="false">)</mo><mi>B</mi><msup><mi>s</mi><mn>2</mn></msup><mi>h</mi><mo>=</mo><mn>24</mn><mi>B</mi><mi>s</mi><msup><mi>h</mi><mn>2</mn></msup><mo>+</mo><mn>4</mn><mi>B</mi><msup><mi>s</mi><mn>2</mn></msup><mi>h</mi></mrow><annotation encoding="application/x-tex">(6 + 2 + 8 + 8)Bsh^2 + (2 + 2)Bs^2h = 24Bsh^2 + 4Bs^2h</annotation></semantics></math></span></p>
<p>backward 的 FLOPs 大致是 forward 的 2 倍，所以 forward + backward 的 FLOPs 大致是 <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>72</mn><mi>B</mi><mi>s</mi><msup><mi>h</mi><mn>2</mn></msup><mo>+</mo><mn>12</mn><mi>B</mi><msup><mi>s</mi><mn>2</mn></msup><mi>h</mi></mrow><annotation encoding="application/x-tex">72Bsh^2 + 12Bs^2h</annotation></semantics></math></span></p>
<p>参考 <a href="https://arxiv.org/pdf/2104.04473.pdf">Megatron-LM 2</a> APPENDIX</p></div></article></main><div class="mt-12"><a href="/">← 返回首页</a></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"postData":{"id":"flops","contentHtml":"\u003cp\u003e模型训练过程中大多数浮点运算都是矩阵乘法，对于一个 \u003cspan class=\"katex\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003em\u003c/mi\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmi\u003en\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003em \\times n\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e 的矩阵 \u003cspan class=\"katex\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eA\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eA\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e 和一个 \u003cspan class=\"katex\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003en\u003c/mi\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmi\u003ep\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003en \\times p\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e 的矩阵 \u003cspan class=\"katex\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eB\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eB\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e，\u003cspan class=\"katex\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eA\u003c/mi\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmi\u003eB\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eA \\times B\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e 需要 \u003cspan class=\"katex\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003em\u003c/mi\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmi\u003en\u003c/mi\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmi\u003ep\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003em \\times n \\times p\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e 次乘法和 \u003cspan class=\"katex\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003em\u003c/mi\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmi\u003en\u003c/mi\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmi\u003ep\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003em \\times n \\times p\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e 次加法，即需要 \u003cspan class=\"katex\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmi\u003em\u003c/mi\u003e\u003cmi\u003en\u003c/mi\u003e\u003cmi\u003ep\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e2mnp\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e FLOPs。\u003c/p\u003e\n\u003ch2\u003eTransformer Architecture 的 FLOPs 计算\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/transformer.png\" alt=\"alt text\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/attention.png\" alt=\"alt text\"\u003e\u003c/p\u003e\n\u003ch3\u003eAttention\u003c/h3\u003e\n\u003cp\u003eQ，K，V transformation:  \u003cspan class=\"katex\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e3\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmi\u003eB\u003c/mi\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmsup\u003e\u003cmi\u003eh\u003c/mi\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/msup\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e3 \\times 2Bsh^2\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan class=\"katex\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eQ\u003c/mi\u003e\u003cmsup\u003e\u003cmi\u003eK\u003c/mi\u003e\u003cmi\u003eT\u003c/mi\u003e\u003c/msup\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eQK^T\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e: \u003cspan class=\"katex\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmi\u003eB\u003c/mi\u003e\u003cmsup\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/msup\u003e\u003cmi\u003eh\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e2Bs^2h\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003eattention over values: \u003cspan class=\"katex\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmi\u003eB\u003c/mi\u003e\u003cmsup\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/msup\u003e\u003cmi\u003eh\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e2Bs^2h\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003epost-attention linear projection: \u003cspan class=\"katex\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmi\u003eB\u003c/mi\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmsup\u003e\u003cmi\u003eh\u003c/mi\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/msup\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e2Bsh^2\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003eFeed Forward Network\u003c/h3\u003e\n\u003cp\u003elinear h-\u003e4h: \u003cspan class=\"katex\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e8\u003c/mn\u003e\u003cmi\u003eB\u003c/mi\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmsup\u003e\u003cmi\u003eh\u003c/mi\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/msup\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e8Bsh^2\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003elinear 4h-\u003eh: \u003cspan class=\"katex\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e8\u003c/mn\u003e\u003cmi\u003eB\u003c/mi\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmsup\u003e\u003cmi\u003eh\u003c/mi\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/msup\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e8Bsh^2\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003eTotal\u003c/h3\u003e\n\u003cp\u003eforward: \u003cspan class=\"katex\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmn\u003e6\u003c/mn\u003e\u003cmo\u003e+\u003c/mo\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmo\u003e+\u003c/mo\u003e\u003cmn\u003e8\u003c/mn\u003e\u003cmo\u003e+\u003c/mo\u003e\u003cmn\u003e8\u003c/mn\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmi\u003eB\u003c/mi\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmsup\u003e\u003cmi\u003eh\u003c/mi\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/msup\u003e\u003cmo\u003e+\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmo\u003e+\u003c/mo\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmi\u003eB\u003c/mi\u003e\u003cmsup\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/msup\u003e\u003cmi\u003eh\u003c/mi\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmn\u003e24\u003c/mn\u003e\u003cmi\u003eB\u003c/mi\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmsup\u003e\u003cmi\u003eh\u003c/mi\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/msup\u003e\u003cmo\u003e+\u003c/mo\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmi\u003eB\u003c/mi\u003e\u003cmsup\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/msup\u003e\u003cmi\u003eh\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e(6 + 2 + 8 + 8)Bsh^2 + (2 + 2)Bs^2h = 24Bsh^2 + 4Bs^2h\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003ebackward 的 FLOPs 大致是 forward 的 2 倍，所以 forward + backward 的 FLOPs 大致是 \u003cspan class=\"katex\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e72\u003c/mn\u003e\u003cmi\u003eB\u003c/mi\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmsup\u003e\u003cmi\u003eh\u003c/mi\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/msup\u003e\u003cmo\u003e+\u003c/mo\u003e\u003cmn\u003e12\u003c/mn\u003e\u003cmi\u003eB\u003c/mi\u003e\u003cmsup\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/msup\u003e\u003cmi\u003eh\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e72Bsh^2 + 12Bs^2h\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e参考 \u003ca href=\"https://arxiv.org/pdf/2104.04473.pdf\"\u003eMegatron-LM 2\u003c/a\u003e APPENDIX\u003c/p\u003e","title":"FLOPs 的计算","date":"2024-04-18"}},"__N_SSG":true},"page":"/posts/[id]","query":{"id":"flops"},"buildId":"wTPBy1ZzrXj1NkuaydzLJ","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>